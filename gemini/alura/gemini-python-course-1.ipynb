{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138728fc",
   "metadata": {},
   "source": [
    "## Curso: https://cursos.alura.com.br/course/gemini-python-criando-ferramentas-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b129a690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import errors, types\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d519e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b55a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: Olá! Sou Bob, e minha paixão e expertise residem no dinâmico mundo do marketing de produtos eletrônicos. Com anos de experiência ajudando a moldar e lançar inovações no mercado, estou sempre atento às tendências e aos dispositivos que realmente fazem a diferença.\n",
      "\n",
      "Estou aqui para apresentar alguns dos produtos que mais me impressionam, e que representam o futuro da tecnologia:\n",
      "\n",
      "*   **Smartphone Xtreme 5G**\n",
      "    Um dispositivo móvel de última geração com conectividade 5G ultrarrápida, câmera profissional e bateria de longa duração.\n",
      "\n",
      "*   **SmartWatch Aura Pro**\n",
      "    Um relógio inteligente que monitora a saúde com precisão, oferece notificações inteligentes e integra-se perfeitamente ao seu ecossistema digital.\n",
      "\n",
      "*   **AeroSound Elite**\n",
      "    Fones de ouvido sem fio com cancelamento de ruído ativo de ponta e áudio de alta fidelidade para uma experiência sonora imersiva.\n",
      "\n",
      "*   **HomeConnect Hub**\n",
      "    Um hub inteligente que unifica e controla todos os dispositivos da sua casa conectada, de iluminação a segurança, com comandos de voz intuitivos.\n",
      "\n",
      "*   **ZenBook Air Ultra**\n",
      "    Um notebook ultrafino e potente, ideal para produtividade em movimento, com design elegante e bateria que dura o dia todo.\n",
      "\n",
      "*   **AdventureCam 360 Pro**\n",
      "    Câmera de ação robusta e compacta, perfeita para capturar aventuras em 360 graus, com estabilização de imagem avançada e resistência à água.\n",
      "\n",
      "*   **GameFlow Console Híbrido**\n",
      "    Um console de jogos versátil que permite jogar tanto na TV quanto em modo portátil, com gráficos impressionantes e uma vasta biblioteca de títulos exclusivos.\n"
     ]
    }
   ],
   "source": [
    "system_instructions = \"\"\"\n",
    "Apresente-se como um especialista em marketing de produtos eletrônicos e seu nome é Bob.\n",
    "Liste apenas os nomes dos produtos e ofereça uma breve descrição de cada um.\n",
    "\"\"\"\n",
    "MODEL_CHOICE = \"gemini-2.5-flash\"\n",
    "prompt = \"\"\n",
    "\n",
    "try:\n",
    "  response = client.models.generate_content(\n",
    "    model=MODEL_CHOICE,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instructions,\n",
    "        temperature=0.3,\n",
    "        top_p=1.0,\n",
    "        top_k=10,\n",
    "        max_output_tokens=4096,\n",
    "      ),\n",
    "    contents=prompt\n",
    "  )\n",
    "  print(f'Resposta: {response.text}')\n",
    "\n",
    "except errors.APIError as e:\n",
    "  print(f\"Error API: {e.message}\")\n",
    "  print(f\"Error Code: {e.code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd8cc5",
   "metadata": {},
   "source": [
    "#### Categorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4363585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_product(product_name: str, possible_categories: list[str]):\n",
    "  system_instructions = f\"\"\"\n",
    "  Você é um especialista em marketing de produtos gerais.\n",
    "  Você deve classificar os produtos que o usuário lhe enviar.\n",
    "  Se apresente como Bob, seu nome.\n",
    "\n",
    "  ## Categorias possíveis:\n",
    "    {possible_categories.split(\",\")}\n",
    "\n",
    "  ## Formato de saída:\n",
    "    Produto: [NOME_PRODUTO]\n",
    "    Categoria: [CATEGORIA]\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.models.generate_content(\n",
    "    model=MODEL_CHOICE,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instructions,\n",
    "        temperature=0.3,\n",
    "        max_output_tokens=4096,\n",
    "      ),\n",
    "    contents=product_name\n",
    "  )\n",
    "\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17673b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o nome do produto:  Iphone 17 Pro Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá! Eu sou o Bob, seu especialista em marketing de produtos.\n",
      "\n",
      "Produto: Iphone 17 Pro Max\n",
      "Categoria: Eletrônicos Verdes\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  possible_categories = \"Eletrônicos Verdes,Moda Sustentável,Produtos de Limpeza Ecológicos,Alimentos Orgânicos, Produto de Higiene Sustentável\"\n",
    "\n",
    "  product = input(\"Digite o nome do produto: \")\n",
    "\n",
    "  try:\n",
    "    product = categorize_product(product_name=product, possible_categories=possible_categories)\n",
    "    print(product)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6b6a4",
   "metadata": {},
   "source": [
    "#### Contador de Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d919f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os tokens do model models/gemini-2.5-flash são: {'input_token_limit': 1048576, 'output_token_limit': 65536}\n",
      "Os tokens do model models/gemini-2.5-pro são: {'input_token_limit': 1048576, 'output_token_limit': 65536}\n",
      "Os tokens do model gemini-2.5-flash para o prompt \"Quais as melhores linguagens de programação para IA?\" são: 12 tokens\n",
      "Os tokens do model gemini-2.5-pro para o prompt \"Quais as melhores linguagens de programação para IA?\" são: 12 tokens\n"
     ]
    }
   ],
   "source": [
    "MODEL_FLASH=\"gemini-2.5-flash\"\n",
    "MODEL_PRO=\"gemini-2.5-pro\"\n",
    "\n",
    "random_prompt = \"Quais as melhores linguagens de programação para IA?\"\n",
    "\n",
    "\n",
    "for m in [MODEL_FLASH, MODEL_PRO]:\n",
    "    model = client.models.get(model=m)\n",
    "    tokens_info_model = {\n",
    "        \"input_token_limit\": model.input_token_limit,\n",
    "        \"output_token_limit\": model.output_token_limit,\n",
    "    }\n",
    "    print(f'Os tokens do model {model.name} são: {tokens_info_model}')\n",
    "\n",
    "\n",
    "for m in [MODEL_FLASH, MODEL_PRO]:\n",
    "    response = client.models.count_tokens(\n",
    "        model=m,\n",
    "        contents=random_prompt\n",
    "    )\n",
    "    print(f'Os tokens do model {m} para o prompt \"{random_prompt}\" são: {response.total_tokens} tokens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398d7a0",
   "metadata": {},
   "source": [
    "#### Selecionador de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1861f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name: str):\n",
    "  try:\n",
    "    with open(file_name, encoding='utf-8') as file:\n",
    "      return file.read()\n",
    "  except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Arquivo não encontrado: {file_name}\")\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Erro ao ler arquivo '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20c0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def resolve_data_path(name: str) -> Path:\n",
    "    p = Path(name)\n",
    "\n",
    "    # Build candidate filenames:\n",
    "    # - If an extension is provided (e.g., .txt, .csv), use it as-is\n",
    "    # - Otherwise, try common options (.csv preferred, then .txt, then raw name)\n",
    "    if p.suffix:\n",
    "        candidates = [p.name]\n",
    "    else:\n",
    "        candidates = [f\"{name}.csv\", f\"{name}.txt\", name]\n",
    "\n",
    "    cwd = Path.cwd()\n",
    "\n",
    "    # Look for /data/<arquivo> from current dir up to parents\n",
    "    for root in [cwd, *cwd.parents]:\n",
    "        data_dir = root / \"data\"\n",
    "        if data_dir.exists():\n",
    "            for fname in candidates:\n",
    "                candidate = data_dir / fname\n",
    "                if candidate.exists():\n",
    "                    return candidate\n",
    "\n",
    "    # Fallback: recursive search under current directory for any candidate\n",
    "    for fname in candidates:\n",
    "        for match in cwd.rglob(fname):\n",
    "            if \"data\" in match.parts:\n",
    "                return match\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"Arquivo '{candidates[0]}' não encontrado. Diretório atual: {cwd}. \"\n",
    "        \"Verifique se a pasta 'data' está no projeto e acessível.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ec7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo selecionado foi: gemini-2.5-flash - 210 tokens \n",
      "\n",
      "Resposta do modelo: \n",
      "\n",
      "Cliente 0 - Eco-consciente, Sustentável, Natural.\n",
      "Cliente 1 - Saudável, Eficiente, Natural.\n",
      "Cliente 2 - Investidor, Sustentável, Ecológico.\n",
      "Cliente 3 - Sustentável, Reutilizável, Orgânico.\n",
      "Cliente 4 - Natural, Ético, Durável.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_instructions = \"\"\"\n",
    "Você é um assistente de IA que ajuda os usuários a gerenciar seus arquivos.\n",
    "\n",
    "Identifique o perfil de compra para cada cliente a seguir.\n",
    "\n",
    "O formato de saída deve ser:\n",
    "\n",
    "Cliente [x] - Descreva o perfil do cliente em 3 palavras.\n",
    "\"\"\"\n",
    "\n",
    "usage_model = MODEL_FLASH\n",
    "\n",
    "csv_path = resolve_data_path(\"lista_de_compras_100_clientes\")\n",
    "user_prompt = read_file(str(csv_path))\n",
    "\n",
    "\n",
    "first_lines = user_prompt.splitlines()[:10]\n",
    "final_prompt = \"\\n\".join(first_lines)\n",
    "\n",
    "qtd_tokens_model_flash = client.models.count_tokens(\n",
    "    model=MODEL_FLASH,\n",
    "    contents=final_prompt,\n",
    ")\n",
    "\n",
    "LIMIT_TOKENS = 3000\n",
    "\n",
    "if qtd_tokens_model_flash.total_tokens >= LIMIT_TOKENS:\n",
    "    usage_model = MODEL_PRO\n",
    "\n",
    "print(f'O modelo selecionado foi: {usage_model} - {qtd_tokens_model_flash.total_tokens} tokens \\n')\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=usage_model,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instructions,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    "    contents=final_prompt,\n",
    ")\n",
    "\n",
    "print('Resposta do modelo: \\n')\n",
    "print(f'{response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2be388",
   "metadata": {},
   "source": [
    "#### Analisador de Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2904a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(file_name: str, model: str = MODEL_FLASH):\n",
    "    system_instructions = \"\"\"\n",
    "            Você é um analisador de sentimentos de avaliações de produtos.\n",
    "            Escreva um parágrafo com até 50 palavras resumindo as avaliações e\n",
    "            depois atribua qual o sentimento geral para o produto.\n",
    "            Identifique também 3 pontos fortes e 3 pontos fracos identificados a partir das avaliações.\n",
    "\n",
    "            # Formato de Saída\n",
    "\n",
    "            Nome do Produto:\n",
    "            Resumo das Avaliações:\n",
    "            Sentimento Geral: [utilize aqui apenas Positivo, Negativo ou Neutro]\n",
    "            Ponto fortes: lista com três bullets\n",
    "            Pontos fracos: lista com três bullets\n",
    "        \"\"\"\n",
    "\n",
    "    txt_path = resolve_data_path(file_name)\n",
    "    user_prompt = read_file(str(txt_path))\n",
    "\n",
    "    print(f'Iniciando análise de sentimento para o produto: {file_name}. Modelo utilizado: {MODEL_FLASH}\\n')\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=system_instructions,\n",
    "                temperature=0.3,\n",
    "            ),\n",
    "            contents=user_prompt\n",
    "        )\n",
    "        print('Resposta do modelo: \\n')\n",
    "        print(f'{response.text}\\n')\n",
    "\n",
    "    except errors.APIError as e:\n",
    "        print(f'Erro ao gerar conteúdo: {e}')\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc10568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise de sentimento para o produto: avaliacoes-Camisetas de algodão orgânico.txt. Modelo utilizado: gemini-2.5-flash\n",
      "\n",
      "Resposta do modelo: \n",
      "\n",
      "Nome do Produto: Camiseta de Algodão Orgânico\n",
      "Resumo das Avaliações: As avaliações destacam a camiseta de algodão orgânico como extremamente confortável, de alta qualidade e durável, mantendo a forma e cor após lavagens. O apelo sustentável e a transparência na produção são pontos fortes. Embora o preço seja superior e a variedade de cores/designs limitada, os consumidores consideram o produto um excelente investimento.\n",
      "Sentimento Geral: Positivo\n",
      "Ponto fortes:\n",
      "*   Conforto superior, textura suave e respirabilidade do tecido.\n",
      "*   Qualidade e durabilidade excepcionais, mantendo forma e cor após lavagens.\n",
      "*   Compromisso com a sustentabilidade, uso de algodão orgânico e transparência na produção.\n",
      "Pontos fracos:\n",
      "*   Variedade limitada de cores e opções de estampas/designs.\n",
      "*   Preço mais elevado em comparação com camisetas convencionais.\n",
      "*   O custo pode ser um impedimento para compras frequentes ou de múltiplas unidades.\n",
      "\n",
      "Iniciando análise de sentimento para o produto: avaliacoes-Jeans feitos com materiais reciclados.txt. Modelo utilizado: gemini-2.5-flash\n",
      "\n",
      "Resposta do modelo: \n",
      "\n",
      "Nome do Produto: Jeans Reciclados\n",
      "\n",
      "Resumo das Avaliações: Os jeans reciclados são amplamente elogiados por seu estilo, conforto e ajuste perfeito, superando expectativas. A qualidade, durabilidade e a iniciativa sustentável são pontos fortes. Embora haja sugestões para mais flexibilidade e variedade de modelos, a satisfação geral é muito alta, tornando-os favoritos.\n",
      "\n",
      "Sentimento Geral: Positivo\n",
      "\n",
      "Pontos fortes:\n",
      "*   Conforto e ajuste perfeito, superando as expectativas para um produto reciclado.\n",
      "*   Qualidade do material e durabilidade, com atenção aos detalhes nas costuras e bolsos.\n",
      "*   Iniciativa sustentável e consciência ecológica, sendo um grande atrativo para os consumidores.\n",
      "\n",
      "Pontos fracos:\n",
      "*   Sugestões para melhorar a flexibilidade do jeans.\n",
      "*   Desejo por mais opções de modelos e estilos, como cintura alta.\n",
      "*   Textura ligeiramente diferente dos jeans tradicionais, embora não comprometa a qualidade.\n",
      "\n",
      "Iniciando análise de sentimento para o produto: avaliacoes-Maquiagem mineral.txt. Modelo utilizado: gemini-2.5-flash\n",
      "\n",
      "Resposta do modelo: \n",
      "\n",
      "Nome do Produto: Maquiagem Mineral\n",
      "Resumo das Avaliações: A maquiagem mineral é amplamente elogiada pelo acabamento natural e luminoso, sendo ideal para peles sensíveis e uso diário. Usuários destacam a longa duração, ingredientes naturais e proteção solar, considerando o preço justo. Apesar de algumas sugestões para aprimorar a seleção de cores e a embalagem, a satisfação geral é muito alta.\n",
      "Sentimento Geral: Positivo\n",
      "Ponto fortes:\n",
      "*   Acabamento natural e luminoso, ideal para peles sensíveis.\n",
      "*   Longa duração, ingredientes naturais e proteção solar.\n",
      "*   Excelente custo-benefício e não irrita a pele.\n",
      "Pontos fracos:\n",
      "*   Seleção de cores poderia ser mais ampla.\n",
      "*   Embalagem e aplicador poderiam ser mais práticos/eficientes.\n",
      "*   A cobertura leve pode necessitar de retoques para alguns usuários.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_files_products_to_analysis = [\n",
    "    \"avaliacoes-Camisetas de algodão orgânico.txt\",\n",
    "    \"avaliacoes-Jeans feitos com materiais reciclados.txt\",\n",
    "    \"avaliacoes-Maquiagem mineral.txt\"\n",
    "]\n",
    "\n",
    "for product in list_files_products_to_analysis:\n",
    "    sentiment_analysis(product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-ml-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
